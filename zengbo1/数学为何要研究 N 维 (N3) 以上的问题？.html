<meta name="referrer" content="no-referrer" />
<meta charset="utf-8" />
处理多维向量，或者多维微积分，多维随机变量的数学规则并不比三维复杂，三维只是n的一个特例而已，因此何乐而不为呢？没有人会发明了数学然后把自己局限在低级的问题里，约束自己的想象力。正如楼上所说，机器学习中的数据维度一般都有2000-3000维。
<br>
反倒是张量。标量（rank 0）的变换是乘以一个实数（复数）；向量（rank 1）的变换是乘以正交矩阵；张量（rank 2）的变换是被两个正交矩阵的厄米sandwich。实际上我还想问，除了rank 2 tensor 以外，还有必要搞rank 3, 4和更高维的 tensor 了吗？
<br>
普通人是不需要了。理论物理好像还需要=
